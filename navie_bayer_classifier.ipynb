{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../Downloads/dataset_NB.txt', delimiter = '\\n', names = ['col'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = data.shape[0]\n",
    "rows_per_partition = int(length / 7)\n",
    "data = data.sample(frac = 1)\n",
    "rows_per_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words_class(s):\n",
    "    words = re.findall(r'\\w{3,}', s)\n",
    "    return (words, int(s[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_prob(words, class_prob, total_features, word_freq, total_words):\n",
    "    culmulative_words_prob = 1\n",
    "    for i in words:\n",
    "        count = 1\n",
    "        if i in word_freq:\n",
    "            count += word_freq[i]\n",
    "        culmulative_words_prob *= count /(total_features + total_words)\n",
    "    return culmulative_words_prob * class_prob\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nav_bayer_text_classification(train, test):\n",
    "    words_list_spam = []\n",
    "    words_list_not = []\n",
    "    count = 0;\n",
    "    for index, row in train.iterrows():\n",
    "#     print((row.col))\n",
    "        words, spam = extract_words_class(row.col)\n",
    "        if spam == 1:\n",
    "            count = count + 1\n",
    "            words_list_spam = words_list_spam + words\n",
    "        else:\n",
    "            words_list_not = words_list_not + words\n",
    "        \n",
    "    total_words_spam = len(words_list_spam)\n",
    "    total_words_not = len(words_list_not)\n",
    "\n",
    "\n",
    "    words_list_spam = [x.lower() for x in words_list_spam]\n",
    "    words_list_not = [x.lower() for x in words_list_not]\n",
    "\n",
    "\n",
    "    word_frequency_spam = dict(Counter(words_list_spam))\n",
    "    word_frequency_not = dict(Counter(words_list_not))\n",
    "\n",
    "\n",
    "    total_features_spam = len(word_frequency_spam)\n",
    "    total_features_not = len(word_frequency_not)\n",
    "\n",
    "\n",
    "    prob_spam = count/train.shape[0]\n",
    "    prob_not = 1 - prob_spam\n",
    "    correct_count = 0\n",
    "    for _, row in test.iterrows():\n",
    "        words, spam = extract_words_class(row.col)\n",
    "        spam_class_prob = cal_prob(words, prob_spam, total_features_spam, word_frequency_spam,total_words_spam )\n",
    "        not_class_prob = cal_prob(words, prob_not, total_features_not, word_frequency_not,total_words_not )\n",
    "#         print(spam_class_prob,not_class_prob )\n",
    "        if spam_class_prob > not_class_prob and spam == 1 or spam_class_prob > not_class_prob and spam == 0:\n",
    "            correct_count += 1\n",
    "    return (correct_count/test.shape[0]) * 100\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[65.49295774647888, 64.08450704225352, 66.90140845070422, 60.56338028169014, 59.859154929577464, 61.97183098591549, 64.08450704225352]\n",
      "63.27967806841047\n"
     ]
    }
   ],
   "source": [
    "folds_7 = []\n",
    "for i in range(7):\n",
    "    test = data.iloc[i*rows_per_partition : (i+1)*rows_per_partition:]\n",
    "    test_index = list(test.index.values.tolist())\n",
    "    train = data.copy(deep=True)\n",
    "    for i in test_index:\n",
    "        train.drop(i, inplace = True)\n",
    "    folds_7.append(nav_bayer_text_classification(train, test))\n",
    "print(folds_7)\n",
    "print(sum(folds_7) / len(folds_7) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
